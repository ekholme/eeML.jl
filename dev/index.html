<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · eeML.jl</title><meta name="title" content="Home · eeML.jl"/><meta property="og:title" content="Home · eeML.jl"/><meta property="twitter:title" content="Home · eeML.jl"/><meta name="description" content="Documentation for eeML.jl."/><meta property="og:description" content="Documentation for eeML.jl."/><meta property="twitter:description" content="Documentation for eeML.jl."/><meta property="og:url" content="https://ekholme.github.io/eeML.jl/"/><meta property="twitter:url" content="https://ekholme.github.io/eeML.jl/"/><link rel="canonical" href="https://ekholme.github.io/eeML.jl/"/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>eeML.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ekholme/eeML.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/ekholme/eeML.jl/blob/master/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="eeML"><a class="docs-heading-anchor" href="#eeML">eeML</a><a id="eeML-1"></a><a class="docs-heading-anchor-permalink" href="#eeML" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/ekholme/eeML.jl">eeML</a>.</p><ul><li><a href="#eeML.LinearRegression-Tuple{}"><code>eeML.LinearRegression</code></a></li><li><a href="#eeML.LinearRegression"><code>eeML.LinearRegression</code></a></li><li><a href="#eeML.binary_crossentropy-Tuple{AbstractVector{&lt;:Integer}, AbstractVector{&lt;:Real}}"><code>eeML.binary_crossentropy</code></a></li><li><a href="#eeML.fit!-Tuple{LinearRegression, AbstractMatrix{&lt;:Real}, AbstractVector{&lt;:Real}}"><code>eeML.fit!</code></a></li><li><a href="#eeML.fit!-Tuple{LogisticRegression, AbstractMatrix{&lt;:Real}, AbstractVector{&lt;:Integer}}"><code>eeML.fit!</code></a></li><li><a href="#eeML.gradient_descent-Tuple{Any, AbstractVector{&lt;:Real}}"><code>eeML.gradient_descent</code></a></li><li><a href="#eeML.mse-Tuple{AbstractVector{&lt;:Real}, AbstractVector{&lt;:Real}}"><code>eeML.mse</code></a></li><li><a href="#eeML.predict-Tuple{LogisticRegression, AbstractMatrix{&lt;:Real}}"><code>eeML.predict</code></a></li><li><a href="#eeML.predict-Tuple{LinearRegression, AbstractMatrix{&lt;:Real}}"><code>eeML.predict</code></a></li><li><a href="#eeML.r_squared-Tuple{AbstractVector{&lt;:Real}, AbstractVector{&lt;:Real}}"><code>eeML.r_squared</code></a></li><li><a href="#eeML.rmse-Tuple{Vector{&lt;:Real}, Vector{&lt;:Real}}"><code>eeML.rmse</code></a></li><li><a href="#eeML.sigmoid-Tuple{Real}"><code>eeML.sigmoid</code></a></li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="eeML.LinearRegression" href="#eeML.LinearRegression"><code>eeML.LinearRegression</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LinearRegression</code></pre><p>A linear regression model object. The struct is mutable so that the <code>fit!</code> function can update the coefficients <code>β</code>.</p><p><strong>Fields</strong></p><ul><li><code>β::Vector{Float64}</code>: The coefficients of the linear model. It is empty until <code>fit!</code> is called.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ekholme/eeML.jl/blob/4ed1a8108fc5399bdf2f40563258ba6b9ccb28aa/src/linear_regression.jl#L1-L8">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="eeML.LinearRegression-Tuple{}" href="#eeML.LinearRegression-Tuple{}"><code>eeML.LinearRegression</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LinearRegression()</code></pre><p>Constructs an untrained <code>LinearRegression</code> model. The coefficients <code>β</code> are initialized as an empty vector and will be populated by the <code>fit!</code> function.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; model = LinearRegression()
LinearRegression(Float64[])</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ekholme/eeML.jl/blob/4ed1a8108fc5399bdf2f40563258ba6b9ccb28aa/src/linear_regression.jl#L13-L23">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="eeML.binary_crossentropy-Tuple{AbstractVector{&lt;:Integer}, AbstractVector{&lt;:Real}}" href="#eeML.binary_crossentropy-Tuple{AbstractVector{&lt;:Integer}, AbstractVector{&lt;:Real}}"><code>eeML.binary_crossentropy</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">binary_crossentropy(y::AbstractVector{&lt;:Integer}, ŷ::AbstractVector{&lt;:Real})</code></pre><p>Calculate the binary cross-entropy loss, commonly used for binary classification.</p><p>Loss is calculated as <code>-mean(y .* log.(ŷ) .+ (1 .- y) .* log.(1 .- ŷ))</code>. A small epsilon <code>eps</code> is used to avoid <code>log(0)</code>.</p><p><strong>Arguments</strong></p><ul><li><code>y::AbstractVector{&lt;:Integer}</code>: The vector of true binary labels (0 or 1).</li><li><code>ŷ::AbstractVector{&lt;:Real}</code>: The vector of predicted probabilities (between 0 and 1).</li></ul><p><strong>Returns</strong></p><ul><li><code>Float64</code>: The binary cross-entropy loss.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ekholme/eeML.jl/blob/4ed1a8108fc5399bdf2f40563258ba6b9ccb28aa/src/loss_funcs.jl#L49-L62">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="eeML.fit!-Tuple{LinearRegression, AbstractMatrix{&lt;:Real}, AbstractVector{&lt;:Real}}" href="#eeML.fit!-Tuple{LinearRegression, AbstractMatrix{&lt;:Real}, AbstractVector{&lt;:Real}}"><code>eeML.fit!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fit!(model::LinearRegression, X::AbstractMatrix{&lt;:Real}, y::AbstractVector{&lt;:Real})</code></pre><p>Train the <code>LinearRegression</code> model using the feature matrix <code>X</code> and target vector <code>y</code>.</p><p>This function mutates the <code>model</code> object by updating its <code>β</code> coefficients. Two fitting methods are available:</p><ul><li><code>:closed_form</code>: (Default) Solves the least-squares problem <code>Xβ = y</code> using Julia&#39;s highly efficient and numerically stable <code>\</code> operator.</li><li><code>:grad_descent</code>: Uses gradient descent to minimize the mean squared error. This can be useful for very large datasets or for educational purposes.</li></ul><p><strong>Arguments</strong></p><ul><li><code>model::LinearRegression</code>: The model to be trained.</li><li><code>X::AbstractMatrix{&lt;:Real}</code>: The matrix of features. It&#39;s common to include a column of ones for an intercept term.</li><li><code>y::AbstractVector{&lt;:Real}</code>: The vector of target values.</li></ul><p><strong>Keywords</strong></p><ul><li><code>fit_method::Symbol=:closed_form</code>: The method to use for fitting. Can be <code>:closed_form</code> or <code>:grad_descent</code>.</li><li><code>kwargs...</code>: Additional keyword arguments passed to the <code>gradient_descent</code> optimizer when <code>fit_method</code> is <code>:grad_descent</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>LinearRegression</code>: The trained model.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ekholme/eeML.jl/blob/4ed1a8108fc5399bdf2f40563258ba6b9ccb28aa/src/linear_regression.jl#L29-L50">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="eeML.fit!-Tuple{LogisticRegression, AbstractMatrix{&lt;:Real}, AbstractVector{&lt;:Integer}}" href="#eeML.fit!-Tuple{LogisticRegression, AbstractMatrix{&lt;:Real}, AbstractVector{&lt;:Integer}}"><code>eeML.fit!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fit!(model::LogisticRegression, X::AbstractMatrix{&lt;:Real}, y::AbstractVector{&lt;:Integer}; kwargs...)</code></pre><p>Train the <code>LogisticRegression</code> model using the feature matrix <code>X</code> and target vector <code>y</code>.</p><p>This function uses <code>gradient_descent</code> to find the optimal coefficients <code>β</code> that minimize the binary cross-entropy loss.</p><p><strong>Arguments</strong></p><ul><li><code>model::LogisticRegression</code>: The model to be trained.</li><li><code>X::AbstractMatrix{&lt;:Real}</code>: The matrix of features. It&#39;s common to include a column of ones for an intercept term.</li><li><code>y::AbstractVector{&lt;:Integer}</code>: The vector of target binary labels (0 or 1).</li></ul><p><strong>Keywords</strong></p><ul><li><code>kwargs...</code>: Keyword arguments passed directly to the <code>gradient_descent</code> optimizer (e.g., <code>learning_rate</code>, <code>max_iter</code>).</li></ul><p><strong>Returns</strong></p><ul><li><code>LogisticRegression</code>: The trained model.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ekholme/eeML.jl/blob/4ed1a8108fc5399bdf2f40563258ba6b9ccb28aa/src/logistic_regression.jl#L9-L26">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="eeML.gradient_descent-Tuple{Any, AbstractVector{&lt;:Real}}" href="#eeML.gradient_descent-Tuple{Any, AbstractVector{&lt;:Real}}"><code>eeML.gradient_descent</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">gradient_descent(loss_func, initial_β; learning_rate=0.01, tol=1e-6, max_iter=1_000, verbose=false)</code></pre><p>Perform gradient descent to find the parameters <code>β</code> that minimize the <code>loss_func</code>.</p><p>This is a general-purpose optimizer. The <code>loss_func</code> must be a function that takes a single vector argument (the parameters <code>β</code>) and returns a scalar loss. For supervised learning problems, you should create a closure that captures your data (<code>X</code>, <code>y</code>).</p><p><strong>Arguments</strong></p><ul><li><code>loss_func</code>: A callable function that accepts a vector <code>β</code> and returns a scalar loss.</li><li><code>initial_β::AbstractVector{&lt;:Real}</code>: The starting values for the parameters <code>β</code>.</li></ul><p><strong>Keywords</strong></p><ul><li><code>learning_rate::Float64=0.01</code>: The step size for each iteration.</li><li><code>tol::Float64=1e-6</code>: The tolerance for convergence. The algorithm stops when the L2 norm of the change in <code>β</code> is less than this value.</li><li><code>max_iter::Int=1_000</code>: The maximum number of iterations.</li><li><code>verbose::Bool=false</code>: If <code>true</code>, prints the iteration number and loss at each step.</li></ul><p><strong>Returns</strong></p><ul><li><code>Vector{Float64}</code>: The optimized parameters <code>β</code>.</li></ul><p><strong>Example</strong></p><p><strong>1. Linear Regression</strong></p><pre><code class="language-julia hljs"># Define a mean squared error loss function for a linear model
X = hcat(ones(100), rand(100, 1)) # Add intercept
true_β = [1.5, -3.0]
y = X * true_β + 0.2 * randn(100)
loss(β) = sum((y - X * β).^2) / length(y)

# Initial guess for parameters
initial_β = rand(2)

# Run optimizer
β_optimized = gradient_descent(loss, initial_β, learning_rate=0.1);
isapprox(β_optimized, true_β, atol=0.1)

# output

true</code></pre><p><strong>2. Logistic Regression</strong></p><p>For logistic regression, we create a closure around the binary cross-entropy loss. This is exactly what the <code>fit!</code> method for <code>LogisticRegression</code> does internally.</p><pre><code class="language-julia hljs"># The loss function captures X and y from its environment
loss_logistic(β) = binary_crossentropy(y_binary, sigmoid(X * β))

# Then you would call the optimizer:
# β_logistic = gradient_descent(loss_logistic, initial_β_logistic)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ekholme/eeML.jl/blob/4ed1a8108fc5399bdf2f40563258ba6b9ccb28aa/src/optimizers.jl#L3-L56">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="eeML.mse-Tuple{AbstractVector{&lt;:Real}, AbstractVector{&lt;:Real}}" href="#eeML.mse-Tuple{AbstractVector{&lt;:Real}, AbstractVector{&lt;:Real}}"><code>eeML.mse</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">mse(y::AbstractVector{&lt;:Real}, ŷ::AbstractVector{&lt;:Real})</code></pre><p>Calculate the Mean Squared Error (MSE) between the true values <code>y</code> and the predicted values <code>ŷ</code>.</p><p>MSE is calculated as <code>mean((y - ŷ).^2)</code>. This is a common loss function for regression problems.</p><p><strong>Arguments</strong></p><ul><li><code>y::AbstractVector{&lt;:Real}</code>: The vector of true values.</li><li><code>ŷ::AbstractVector{&lt;:Real}</code>: The vector of predicted values.</li></ul><p><strong>Returns</strong></p><ul><li><code>Float64</code>: The Mean Squared Error.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ekholme/eeML.jl/blob/4ed1a8108fc5399bdf2f40563258ba6b9ccb28aa/src/loss_funcs.jl#L30-L43">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="eeML.predict-Tuple{LinearRegression, AbstractMatrix{&lt;:Real}}" href="#eeML.predict-Tuple{LinearRegression, AbstractMatrix{&lt;:Real}}"><code>eeML.predict</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">predict(model::LinearRegression, X::AbstractMatrix{&lt;:Real})</code></pre><p>Make predictions using a trained <code>LinearRegression</code> model.</p><p><strong>Arguments</strong></p><ul><li><code>model::LinearRegression</code>: The trained model containing coefficients <code>β</code>.</li><li><code>X::AbstractMatrix{&lt;:Real}</code>: The matrix of features for which to make predictions.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ekholme/eeML.jl/blob/4ed1a8108fc5399bdf2f40563258ba6b9ccb28aa/src/linear_regression.jl#L78-L86">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="eeML.predict-Tuple{LogisticRegression, AbstractMatrix{&lt;:Real}}" href="#eeML.predict-Tuple{LogisticRegression, AbstractMatrix{&lt;:Real}}"><code>eeML.predict</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">predict(model::LogisticRegression, X::AbstractMatrix{&lt;:Real}; threshold::Union{Float64, Nothing}=0.5)</code></pre><p>Make predictions using a trained <code>LogisticRegression</code> model. Returns class labels by default.</p><p><strong>Arguments</strong></p><ul><li><code>model::LogisticRegression</code>: The trained model.</li><li><code>X::AbstractMatrix{&lt;:Real}</code>: The matrix of features for which to make predictions.</li><li><code>threshold::Union{Float64, Nothing}=0.5</code>: The probability threshold for classifying as 1. If <code>nothing</code>, raw probabilities are returned.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ekholme/eeML.jl/blob/4ed1a8108fc5399bdf2f40563258ba6b9ccb28aa/src/logistic_regression.jl#L44-L53">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="eeML.r_squared-Tuple{AbstractVector{&lt;:Real}, AbstractVector{&lt;:Real}}" href="#eeML.r_squared-Tuple{AbstractVector{&lt;:Real}, AbstractVector{&lt;:Real}}"><code>eeML.r_squared</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">r_squared(y::Vector{&lt;:Real}, ŷ::Vector{&lt;:Real})</code></pre><p>Calculate the R-squared (coefficient of determination) value.</p><p>R-squared measures the proportion of the variance in the dependent variable that is predictable from the independent variable(s). It is calculated as <code>1 - (SS_res / SS_tot)</code>, where <code>SS_res</code> is the sum of squared residuals and <code>SS_tot</code> is the total sum of squares.</p><p><strong>Arguments</strong></p><ul><li><code>y::AbstractVector{&lt;:Real}</code>: The vector of true values.</li><li><code>ŷ::AbstractVector{&lt;:Real}</code>: The vector of predicted values.</li></ul><p><strong>Returns</strong></p><ul><li><code>Float64</code>: The R-squared value.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; r_squared([1, 2, 3, 4], [1.1, 1.9, 3.2, 3.8])
0.98</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ekholme/eeML.jl/blob/4ed1a8108fc5399bdf2f40563258ba6b9ccb28aa/src/score.jl#L4-L23">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="eeML.rmse-Tuple{Vector{&lt;:Real}, Vector{&lt;:Real}}" href="#eeML.rmse-Tuple{Vector{&lt;:Real}, Vector{&lt;:Real}}"><code>eeML.rmse</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">rmse(y::AbstractVector{&lt;:Real}, ŷ::AbstractVector{&lt;:Real})</code></pre><p>Calculate the Root Mean Squared Error (RMSE) between the true values <code>y</code> and the predicted values <code>ŷ</code>.</p><p>RMSE is calculated as <code>sqrt(mean((y - ŷ).^2))</code>.</p><p><strong>Arguments</strong></p><ul><li><code>y::AbstractVector{&lt;:Real}</code>: The vector of true values.</li><li><code>ŷ::AbstractVector{&lt;:Real}</code>: The vector of predicted values.</li></ul><p><strong>Returns</strong></p><ul><li><code>Float64</code>: The Root Mean Squared Error.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; rmse([1, 2, 3], [1.1, 2.2, 2.9])
0.14142135623730964</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ekholme/eeML.jl/blob/4ed1a8108fc5399bdf2f40563258ba6b9ccb28aa/src/loss_funcs.jl#L1-L20">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="eeML.sigmoid-Tuple{Real}" href="#eeML.sigmoid-Tuple{Real}"><code>eeML.sigmoid</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">sigmoid(x)</code></pre><p>Calculate the sigmoid function <code>1 / (1 + exp(-x))</code>.</p><p>This function is broadcasted element-wise for array inputs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/ekholme/eeML.jl/blob/4ed1a8108fc5399bdf2f40563258ba6b9ccb28aa/src/utils.jl#L1-L7">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Thursday 4 September 2025 15:03">Thursday 4 September 2025</span>. Using Julia version 1.11.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
